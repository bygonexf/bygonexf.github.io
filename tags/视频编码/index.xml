<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>视频编码 on 著花未</title>
    <link>https://imfaye.me/tags/%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81/</link>
    <description>Recent content in 视频编码 on 著花未</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Faye</copyright>
    <lastBuildDate>Wed, 20 Apr 2022 17:04:37 +0800</lastBuildDate><atom:link href="https://imfaye.me/tags/%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>端到端图像/视频压缩里的熵模型</title>
      <link>https://imfaye.me/post/e2e-entropy-model/</link>
      <pubDate>Wed, 20 Apr 2022 17:04:37 +0800</pubDate>
      
      <guid>https://imfaye.me/post/e2e-entropy-model/</guid>
      <description>概率分布与熵编码 在端到端图像/视频压缩模型中，我们需要去尽可能精准地模拟待编码元素值的概率分布。一方面是为了更精确地进行码率估计，另一方面也是因为更精准的概率分布建模能使得熵编码环节更好地消除统计冗余节省码字。
建模出概率分布后，在实际熵编码中，就可以通过概率分布生成熵编码器所需要的概率表。
多说一句，在传统编解码里，通常熵编码会采用自适应模型，即随着编码字符的输入，不断更新概率分布（自适应模型相比静态模型效率更高，符合局部性原理，适应符号概率忽大忽小的波动，如果能合理地利用上下文信息压缩效率可以远超静态模型）。然而在端到端压缩模型里，通常直接通过网络生成独立的概率分布的参数，不会随着编码过程更新概率表。
量化不可导 这个没什么好说的，量化四舍五入的取整操作显然是不可导的，所以在训练的时候可以通过加均匀噪声来替换四舍五入的操作。
在训练阶段，我们会通过给待编码元素值加上-0.5到0.5的均匀噪声来替代量化操作。而实际推理的时候，就正常进行量化。
均匀噪声涉及到的概率关系 首先明确一下这几条线分布代表什么。
$p_{y_i}$：编码空间元素值的概率密度函数
$p_{\tilde{y_i}}$：$y_i$ 加上均匀噪声后的概率密度函数
$p_{\hat{y_i}}$：$y_i$量化后的概率质量函数（量化后就成了离散型变量了）
均匀噪声其实就是均匀分布 $U(-0.5, 0.5)$，$y_i$ 加上均匀噪声得到 $\tilde{y_i}$，两个独立的连续随机变量的和的概率分布公式是 $f_{X+Y}(z) = \int_{-\infty}^{\infty} f_X(x) f_Y(z-x) ,\mathrm{d}x$，直观来说也很好理解，对于任意 $\tilde{y_i}$ 值为 $c$，可能加均匀噪声得到 $c$ 的 $y_i$ 取值范围其实就是 $c-0.5$ 到 $c+0.5$，$p_{\tilde{y_i}}$ 在 $c$ 点的值其实就可以通过 $p_{y_i}$ 在 $c-0.5$ 到 $c+0.5$ 的积分得出。
对于每个整数点，也自然符合上述描述。
而这样一来，加均匀噪声得到的 $p_{\tilde{y_i}}$ 最妙的性质就在于，在每个整数点 $p_{\tilde{y_i}}$ 的值和实际量化得到的离散变量 $p_{\hat{y_i}}$ 在这一点的概率质量相等。
所以说，加均匀噪声这一操作，本质上类似于在给 $p_{\hat{y_i}}$ 的概率质量函数作插值，类似于一个连续松弛 (continuous relaxation) 的操作。
此外，我们在端到端模型里通常去建模的也就是这个 $p_{y_i}$，而这里其实是假设 $p_{y_i}$ 近似一个拉普拉斯分布，实际代码实现中，有一部分模型采用拉普拉斯分布去建模，也有一部分模型，比如 CompressAI，是采用高斯分布去建模的。
CompressAI 代码中的熵模型 以其中的 GaussianConditional 熵模型为例，稍微讲一下实际实现的时候一些常见操作。
def forward( self, inputs: Tensor, scales: Tensor, means: Optional[Tensor] = None, training: Optional[bool] = None, ) -&amp;gt; Tuple[Tensor, Tensor]: if training is None: training = self.</description>
    </item>
    
    <item>
      <title>可变形卷积与光流</title>
      <link>https://imfaye.me/post/dcn-and-optical-flow/</link>
      <pubDate>Sun, 20 Feb 2022 17:04:37 +0800</pubDate>
      
      <guid>https://imfaye.me/post/dcn-and-optical-flow/</guid>
      <description>可变形卷积代码篇 一个调用 from mmcv.ops import ModulatedDeformConv2d 的例子：
def forward(self, input): x = self.offset_mask_conv(input) o1, o2, mask = torch.chunk(x, 3, dim=1) offset = torch.cat((o1, o2), dim=1) mask = torch.sigmoid(mask) output = self.dcnv2(input, offset, mask) return output 总而言之 offset 的 size 就是 2*kernel[0]*kernel[1] ，想一想，原来我们求偏移的时候，会把 B*H*W*C 的图像送入普通卷积得到 B*H*W*2C 得到偏移，也就是每个通道每个位置点都有 x 和 y 两个方向的偏移量。
对 DCN 来说，每个通道都做一样的处理，也就是只需要对每个位置点存卷积核每个点的 x 和 y 的偏移，所以就是 B*H*W*(2*kernel_size) 。
关于 mask:：置信 mask，并非必需，不作展开了
所以 offset 和 mask 一起就是 B*H*W*(3*kernel_size)
关于 deform_groups：本来是所有通道公用，也可以改成划成几组，组数就是 deform_groups，那这样就是 B*H*W*(group_num*3*kernel_size)</description>
    </item>
    
    <item>
      <title>一些传统的熵编码方法</title>
      <link>https://imfaye.me/post/entropy-coding/</link>
      <pubDate>Sun, 05 Dec 2021 13:09:24 +0000</pubDate>
      
      <guid>https://imfaye.me/post/entropy-coding/</guid>
      <description>传统熵模型 算术编码 (Arithmetic Coding) 流程 （以静态模型举例）
假设有一段数据需要编码，统计里面所有的字符和出现的次数。编码从初始区间 (0, 1] 开始。 在当前区间内根据各字符概率划分子区间。 读入字符，找到该字符落入的子区间，将区间更新为该子区间，并重复 2, 3 步骤 最后得到的区间 [low, high) 中任意一个小数以二进制形式输出即得到编码的数据 例子如下：
实现细节 最后结果是一个小数，我们不能简单地用一个 double 类型去表示和计算这个小数，因为根据数据的复杂程度，这个小数可能任意长，小数点后可能会有成千上万位。
然而，小数点后的数据前几位很有可能是在过程中是可以不断提前确定的。例如如果当前区间为 [0.14432, 0.1456)，高位的 0.14 可以提前确定，14已经可以输出了。那么小数点可以向后移动两位，区间变成 [0.432, 0.56)，在此基础上进行后面的计算。这样编码区间永远保持在一个有限的精度要求上。
上述是基于十进制的，实际数字是用二进制表示的，当然原理是一样的，用十进制只是为了表述方便。
静态模型 → 自适应模型 静态模型在初始时对完整的数据统计完概率分布，之后不再更新概率分布；自适应模型随着字符的输入会不断更新概率分布。
静态模型的缺点在于：
在压缩前对信息内字符进行统计的过程会消耗大量时间。 对较长的信息，静态模型统计出的符号概率是该符号在整个信息中的出现概率，而自适应模型可以统计出某个符号在某一局部的出现概率或某个符号相对于某一上下文的出现概率，换句话说，自适应模型得到的概率分布将有利于对信息的压缩（可以说结合上下文的自适应模型的信息熵建立在更高的概率层次上，其总熵值更小），好的基于上下文的自适应模型得到的压缩结果将远远超过静态模型。 例如一段码流，某符号在前面出现概率较大而后面概率小，甚至忽大忽小，采用自适应模型就可以更好的适应这样的变动，压缩效率会比静态模型更高。主流视频编码标准如H.264/H.265都使用自适应模型。
算术编码 vs 哈夫曼编码 首先说结论，算术编码压缩效率更高，哈夫曼编码复杂度更低。
这两种编码，或者说熵编码的本质是，概率越小的字符，用更多的 bit 去表示，这反映到概率区间上就是，概率小的字符所对应的区间也小，因此这个区间的上下边际值的差值越小，为了唯一确定当前这个区间，则需要更多的数字去表示它。
哈夫曼编码由于不断地二叉，它的子区间总是 $\frac{1}{2}$ 的幂次方。而算术编码可以做到严格按照概率的大小等比例划分子区间。所以哈夫曼编码只是算术编码一种粗略的近似。
CABAC CABAC（Context-based Adaptive Binary Arithmetic Coding），CABAC 被视频标准H.264/H.265所采用。
CABAC可以分为二值化、上下文建模和二进制算术编码三个步骤。
其中上下文建模相当于把整段码流进行了再次的细分，把相同条件下的字符bin（比如块大小/亮度色度/语法元素/扫描方式/周围情况等）归属于某个context，形成一个比较独立的子队列而进行编码，其更新只与当前的状态和当前字符是否MPS有关（换句话说，只和历史该子队列编码字符和当前字符有关），而与别的子队列/字符是无关的。当然输出码字往往是根据规则而“混”在一起的。
CABAC虽然性能很好，但也存在以下几点不足：
复杂度过高，不易并行处理。存在块级依赖（左/上角的块没有码率估计/熵编码，后继块就无法得到更新后的状态，从而无法开始码率估计/熵编码）、Bin级依赖（同一个子队列的bin存在前后依赖性，后继的bin要等前面bin编完后才能得到更新后的上下文状态）以及编码的几个环节依赖，这些依赖性会影响编码器的并行实现。 计算精度问题。为简化计算，CABAC采用128个状态来近似，根据原来状态和当前符号性质查表得到下个状态。这个过程中会有一些精度的损失。另外，如果当一连串的MPS到来，状态到达62后就不会继续改变，只会“原地踏步”。换句话说，当概率到达0.01975时就不会随着符号继续变小，这样会影响压缩效率。 Context的设计问题。部分context利用频率很低，在测试中平均一帧都用不到几次，而有的context使用频率很高，需要进一步的优化。 区间编码 (Range Coding) 区间编码可以看为算术编码的一个变种，比算术编码压缩效率略小，但运算速度近乎是算术编码的两倍。
区间编码在整数（任意底）空间中进行进行计算，而算术编码的区间总是以小数的形式进行迭代。其他部分都几乎一样。
端到端熵模型 Todo&amp;hellip;</description>
    </item>
    
    <item>
      <title>图像质量评价指标(MSE, PSNR, MS-SSIM)</title>
      <link>https://imfaye.me/post/image-quality-evaluation-metrics/</link>
      <pubDate>Thu, 02 Dec 2021 23:35:47 +0000</pubDate>
      
      <guid>https://imfaye.me/post/image-quality-evaluation-metrics/</guid>
      <description>如何评价重建图像的质量：比较重建图像与原始图像的可视误差。
MSE Mean Squared Error, 均方误差
$MSE = \frac{1}{N}\sum\limits_{i=1}^{N}(x_i-y_i)^2$
两者越接近，MSE 越小。MSE 损失的范围为 0 到 ∞。
PSNR Peak Signal to Noise Ratio，峰值信噪比，即峰值信号的能量与噪声的平均能量之比，通常取 log 单位为分贝。
$PSNR = 10 log_{10}\frac{MaxValue^2}{MSE}$
从式子可以看出 PSNR 可以理解为 MSE 的另一种表达形式。与 MSE 相反的是，重建图像质量越好，PSNR 数值越大。
对于图像来说，像素点数值以量化方式保存，八比特位深的情况，取值范围为 [0, 255]，$MaxValue$ 就是 255。
SSIM MSE 与 PSNR 的问题是，在计算每个位置上的像素差异时，其结果仅与当前位置的两个像素值有关，与其它任何位置上的像素无关。这种计算差异的方式仅仅将图像看成了一个个孤立的像素点，而忽略了图像内容所包含的一些视觉特征，特别是图像的局部结构信息。而图像质量的好坏极大程度上是一个主观感受，其中结构信息对人主观感受的影响非常之大。
而 SSIM (Structural Similarity，结构相似性) 就试图解决这个问题
SSIM 由三部分组成：
亮度对比 平均灰度作为亮度测量： $\mu_x = \frac{1}{N}\sum\limits_{i=1}^{N}x_i$ 亮度对比函数： $l(x,y) = \frac{2\mu_x\mu_y + C_1}{\mu_x^2+\mu_y^2+C_1}$ 对比度对比 灰度标准差作为对比度测量： $\sigma_x={(\frac{1}{N-1}\sum\limits_{i=1}^N{(x_i-\mu_x)}^2)}^{\frac{1}{2}}$ 亮度对比函数： $c(x,y)=\frac{2\sigma_x\sigma_y+C_2}{\sigma_x^2+\sigma_y^2+C_2}$ 结构对比 结构测量： $\frac{x-\mu_x}{\sigma_x}$ 结构对比函数： $s(x,y) = \frac{\sigma_{xy}+C_3}{\sigma_x\sigma_y + C_3}$ SSIM 函数：</description>
    </item>
    
    <item>
      <title>AVS3 编码位流</title>
      <link>https://imfaye.me/post/avs3-bitstream/</link>
      <pubDate>Thu, 01 Apr 2021 17:28:29 +0000</pubDate>
      
      <guid>https://imfaye.me/post/avs3-bitstream/</guid>
      <description>概述 视频序列是位流的最高层语法结构。
帧由一个亮度样本矩阵和两个色度样本矩阵构成。场由构成帧的三个样本矩阵中相间的行构成。奇数行构成顶场，偶数行构成底场。
视频序列头由视频序列起码码开始，后面跟着一串编码图像数据。序列头可在位流中重复出现，称为重复序列头。使用重复序列头的主要目的是支持对视频序列的随机访问。
一副图像可以是一帧或一场，其编码数据由图像起始码开始，到序列起始码、序列结束码或下一个图像起始码结束。
片是图像中的矩形区域，包含若干最大编码单元在图像内的部分，片之间不应重叠。
图像划分为最大编码单元，最大编码单元之间不应重叠，最大编码单元左上角的样本不应超出图像边界，最大编码单元右下角的样本可超出图像边界。
最大编码单元划分为一个或多个编码单元，由编码树决定。编码单元划分为一个或多个变换块。
码流结构及语义描述 视频序列 序列头 sequence_header
视频序列起始码、档次标号、级别标号、知识位流标志、知识图像允许标志、知识位流重复序列头标志、逐行序列标志、场图像序列标志、水平尺寸、垂直尺寸、色度格式、样本精度、编码样本精度、宽高比、帧率代码、比特率低位、比特率高位、低延迟、时间层标识允许标志、位流缓冲区尺寸、最大解码图像缓冲区大小、参考图像队列 1 索引存在标志、参考图像队列相同标志、参考图像队列配置集数、默认活跃参考图像数、最大编码单元尺寸、最小编码单元尺寸、划分单元最大比例、编码树最大划分次数、最小四叉树尺寸、最大二叉树尺寸、最大扩展四叉树尺寸、加权量化允许标志、加权量化矩阵加载标志、二次变换允许标志、样值偏倚补偿允许标志、自适应修正滤波允许标志、仿射运动补偿允许标志、对称运动矢量差模式允许标志、脉冲编码调制模式允许标志、自适应运动矢量精度允许标志、候选历史运动信息数、帧内预测滤波允许标志、高级运动矢量表达模式允许标志、运动矢量精度扩展模式允许标志、色度两步预测模式允许标志、帧内衍生模式允许标志、衍生模式划分边长最大尺寸、基于位置的变换允许标志、图像重排序延迟、跨片环路滤波允许标志、片划分一致性标志、参考同位置片标志、统一片大小标志、片宽度、片高度
视频编辑码和视频序列结束码
视频编辑码 video_edit_code
紧跟其后的第一幅 I 图像后续的 B 图像可能因缺少参考图像而不能正确解码
视频序列结束码 video_sequence_end_code
标识视频序列的结束。如果 POI（显示顺序索引），如果 POI 的值大于 $(2^{32}-1)$，位流中应插入一个视频序列结束码。
参考图像队列配置集
参考知识图像标志、知识图像索引标志、被参考的知识图像索引、参考图像数、参考图像 DOI 差值绝对值、参考图像 DOI 差值符号
自定义加权量化矩阵
加权量化矩阵系数
图像 帧内预测图像头
帧内预测图像起始码、BBV 延时、时间编码标志、时间编码、解码顺序索引、知识图像索引、时间层标识、图像输出延迟、引用参考图像队列配置集标志、引用参考图像队列配置集索引、BBV 检测次数、逐行帧标志、图像编码结构标志、顶场在先、重复首场、顶场场图像标志、固定图像量化因子、去块滤波禁用标志、去块滤波参数标志、$\alpha$ 和 C 索引的偏移、$\beta$ 索引的偏移、色度量化参数禁用标志、色度量化参数增量 Cb、色度量化参数增量 Cr、图像加权量化允许标志、图像加权量化数据加载索引、加权量化参数索引、加权量化矩阵模型、加权量化参数增量 1、加权量化参数增量 2、图像自适应修正滤波允许标志
帧间预测图像头
帧间预测图像起始码、随机访问正确解码标志、图像编码方式、活跃参考图像数重载标志、活跃参考图像数、仿射预测子块尺寸标志
片
片起始码、固定片量化银子标志、片量化因子、片样值偏移补偿允许标志、高级熵编码字节对齐填充位、最大编码单元量化参数增量、样值偏移补偿合并方式索引、样值偏移补偿模式、样值偏移补偿区间模式偏移绝对值、样值偏移补偿区间模式偏移值符号值、样值偏移补偿区间模式起始偏移子区间位置、样值偏移补偿区间模式起始偏移子区间位置差、样值偏移补偿模式偏移值、样值偏移补偿边缘模式类型、最大编码单元自适应修正滤波允许标志、熵编码最大编码单元填充位、片结束码
编码树 四叉树划分标志、编码单元预测模式、二叉树扩展四叉树划分标志、二叉树扩展四叉树划分类型标志、二叉树扩展四叉树划分方向标志
编码单元 跳过模式标志、高级运动矢量表达模式标志、仿射模式标志、直接模式标志、帧内编码单元标志、基础运动矢量索引、运动矢量偏移量索引、运动矢量方向索引、仿射运动矢量索引、衍生模式划分标志、衍生模式划分方向、水平四叉衍生模式划分标志、垂直四叉衍生模式划分标志、水平非对称衍生模式标志、仿射自适应运动矢量精度索引、自适应运动矢量精度索引、编码单元子类型索引、预测参考模式、对称运动矢量差标志、运动矢量精度扩展模式标识、帧内亮度预测模式、帧内色度预测模式、帧内预测滤波标志、L0 预测单元参考索引、L0 运动矢量水平分量差绝对值、L0 运动矢量垂直分量差绝对值、L0 运动矢量水平分量差符号值、L0 运动矢量垂直分量差符号值、仿射帧间模式L0 运动矢量水平分量差绝对值、仿射帧间模式 L0 运动矢量垂直分量差绝对值、仿射帧间模式 L0 运动矢量水平分量差符号值、仿射帧间模式 L0 运动矢量垂直分量差符号值、L1&amp;hellip;、变换块系数标志、基于位置的变换块标志、Cb 变换块编码模板、Cr 变换块编码模板、亮度变换块编码模板</description>
    </item>
    
    <item>
      <title>H.265/HEVC 预测编码 笔记</title>
      <link>https://imfaye.me/post/prediction-coding/</link>
      <pubDate>Wed, 31 Mar 2021 17:04:49 +0000</pubDate>
      
      <guid>https://imfaye.me/post/prediction-coding/</guid>
      <description>视频预测编码技术 预测编码是指利用已编码的一个或几个样本值，根据某种模型或方法，对当前的样本值进行预测，并对样本真实值和预测值之间的差值进行编码。
帧内预测编码 随着离散余弦变换 (DCT) 在图像、视频编码中的广泛应用，帧内预测转为在频域进行，如相邻块 DC 系数的差分编码等。由 DCT 的性质可知，DC 系数仅能反映当前块像素值的平均大小，因此上述频域中基于 DC 系数的帧内预测无法反映出视频的纹理信息，这限制了频域帧内预测的发展。
H.264/AVC 标准中使用基于块的空域帧内预测方法，规定了若干种预测模式，每种模式都对应一种纹理方向（DC 模式除外），当前块预测像素由其预测方向上相邻块的边界重建像素生成。该方法使得编码器能根据视频内容特征自适应地选择预测模式。
H.264/AVC 使用拉格朗日率失真优化 (RDO) 进行模式选择。它为每一种模式计算其拉格朗日代价： $$ J = D + \lambda \cdot R $$ 其中，$D$ 表示当前预测模式下地失真，$R$ 表示编码当前预测模式下所有信息（如变换系数、模式细腻些、宏块划分方式等）所需的比特数。最优的预测模式不一定满足残差最小，而应指残差信号经过其他编码模块后最终的编码性能最优。
H.264/AVC 标准及后来的 FRExt 扩展层一共规定了 3 种大小的亮度帧内预测块：4 × 4、8 × 8 以及 16 × 16。其中 4 × 4 和 8 × 8 块包含 9 种预测模式，16 × 16 块包含 4 种预测模式。色度分量的帧内预测都是基于 8 × 8 大小的块进行的，也有 4 种预测模式。
帧间预测编码 帧间预测编码原理 目前主要的视频编码标准帧间预测部分都采样了基于块的运动补偿技术。其主要原理是为当前图像的每个像素块在之前已编码图像中寻找一个最佳匹配块，该过程被称为运动估计 (Motion Estimation, ME)。其中被参考的图像称为参考图像 (Reference Frame)，参考块到当前像素块的位移称为运动向量 (Motion Vector, MV)，当前像素块与参考块的差值称为预测残差 (Prediction Residual)。</description>
    </item>
    
    <item>
      <title>H.265/HEVC 编码结构 笔记</title>
      <link>https://imfaye.me/post/video-coding-structure/</link>
      <pubDate>Wed, 31 Mar 2021 11:34:13 +0000</pubDate>
      
      <guid>https://imfaye.me/post/video-coding-structure/</guid>
      <description>名词一览 GOP (Group of Pictures) - 图像组 IDR (Instantaneous Decoding Refresh) - 即时解码刷新 Slice - 片 SS (Slice Segment) - 片段 CTU (Coding Tree Unit) - 树形结构单元 CTB (Coding Tree Block) - 树形编码块 CU (Coding Unit) - 编码单元 SPS (Sequence Parameter Set) - 序列参数集 PPS (Picture Parameter Set) - 图像参数集 CVS (Coded Video Sequence) - 一个 GOP 编码后生成的压缩数据 VPS (Video Parameter Set) - 视频参数集 编码结构概述 编码结构 视频序列分隔为若干个图像组 (GOP)。
存在两种 GOP 类型：</description>
    </item>
    
    <item>
      <title>多媒体基础知识</title>
      <link>https://imfaye.me/post/multimedia-basics/</link>
      <pubDate>Mon, 29 Mar 2021 15:10:25 +0000</pubDate>
      
      <guid>https://imfaye.me/post/multimedia-basics/</guid>
      <description>图像数值表示 分辨率 分辨率的基础单位是像素。1280 * 720 P 的分辨率代表共有 1280 * 720 个像素点。
一台物理设备出厂时就已经定下了它所能拥有的最大像素点是多少。电脑显示屏调整分辨率是系统通过运算来给出模拟色彩块填充适配的。
下述像素排列方式内容为 expansion pack，可略过。
像素排列方式 标准 RGB 排列 LCD 屏幕上常采用标准 RGB 排列，会将一个像素分为 3 个子像素并排排列，通过红、绿、蓝滤色片将 LCD 背光模组的白光过滤后形成相应的 RGB 子像素排列。当需要显示不同颜色的时候，3 个子像素以不同的亮度发光，在视觉上会混合成所需要的颜色。
PenTile 排列 PenTile 排列多见于 OLED 屏幕上，因子像素呈现钻石排列而得名。PenTile 排列的每个像素由红、绿和蓝、绿子像素组合而成，绿色像素是完整的，而红蓝像素相比传统 RGB 排列各减少二分之一，子像素总数减少了约三分之一。
不像标准 RGB 排列每个像素更加独立，PenTile 排列在显示许多内容时需要借用相邻像素，显示精细内容时同分辨率下相较标准 RGB 排列的屏幕细腻度不足。
蓝色 OLED 的发光效率要比红色和绿色低，达到相同的发光强度必须使用更高的通过电流，因而蓝色像素衰减速度更快，也就会加速“烧屏”现象的产生。
YUV 表示方式 对于视频裸数据而言，更多使用 YUV 数据格式显示。
Y 表示明亮度 (Luminance / Luma)，即灰阶值 U、V 表示色度 (Chrominance / Chroma)，描述色调饱和度 亮度通过 RGB 输入信号来建立，方法是将 RGB 信号的特定部分叠加到一起。色度定义了颜色的色彩和饱和度，分别用 Cr 和 Cb 表示。Cr 表示 RGB 输入信号红色部分与 RGB 亮度值之间的差异，Cb 表示 RGB 输入信号蓝色部分与 RGB 信号亮度值之间的差异。</description>
    </item>
    
  </channel>
</rss>
