<!DOCTYPE html>
<html><head>
<title>端到端图像/视频压缩里的熵模型</title>




<meta charset="utf-8">
<meta name="X-UA-Compatible" content="IE=edge">
<meta name="google-site-verification" content="">
<meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
<meta content="telephone=no" name="format-detection">
<meta name="description" content="理论&amp;代码分析">
<meta name="renderer" content="webkit">
<meta name="theme-color" content="#ffffff">



<meta property="og:title" content="端到端图像/视频压缩里的熵模型" />
<meta property="og:description" content="理论&amp;代码分析" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://imfaye.me/post/e2e-entropy-model/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2022-04-20T17:04:37+08:00" />
<meta property="article:modified_time" content="2022-04-20T17:04:37+08:00" /><meta property="og:site_name" content="My Blog" />






<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="端到端图像/视频压缩里的熵模型"/>
<meta name="twitter:description" content="理论&amp;代码分析"/>










  




<link rel="icon" href="https://imfaye.me/img/wind.png">



      <script src="/js/toc.js"></script>
    
    <link type="text/css" rel="stylesheet" href="/vendor/css/bootstrap.min.css">
<link rel="stylesheet" href="/scss/journal.min.d4c42cc03dd5885ad6a856f72cdc8991e948d78f13915e5ad7a9ea75041f0501.css" integrity="sha256-1MQswD3ViFrWqFb3LNyJkelI148TkV5a16nqdQQfBQE=" media="screen">



<link rel="stylesheet" href="/scss/dark-mode.min.b063970adbc0451db461a3b3a99c3ac07ae784200123238e4bc8fc340e6b69ce.css" integrity="sha256-sGOXCtvARR20YaOzqZw6wHrnhCABIyOOS8j8NA5rac4=" media="screen">


<link rel="stylesheet"
          href="https://fonts.googleapis.com/css?family=Material+Icons">




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css" integrity="sha384-RZU/ijkSsFbcmivfdRBQDtwuwVqK7GMOw6IMvKyeWL2K5UAlyp6WonmB8m7Jd0Hn" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js" integrity="sha384-pK1WpvzWVBQiP0/GjnvRxV4mOb0oxFuyRxJlk6vVw146n3egcN5C925NCP7a7BY8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js" integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          
          
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\(', right: '\\)', display: false},
              {left: '\\[', right: '\\]', display: true}
          ],
          
          throwOnError : false
        });
    });
</script>
















</head>
<body>
    	<div id="app"><div id="sideContainer" class="side-container">
    
    <a class="a-block nav-head false" href="https://imfaye.me/">
    
        <div class="nav-title">
            PIKA☆NCHI
        </div>
        
        <div class="nav-subtitle">
            Faye&#39;s Blog
        </div>
        
    </a>

    <div class="nav-link-list">
        
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/posts">
                归档
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/categories">
                分类
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/tags">
                标签
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/about">
                关于
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/index.xml">
                RSS
            </a>
            
        
    </div>

    

    <div class="nav-footer">
        
Hugo Theme <a href="https://github.com/amazingrise/hugo-theme-diary">Diary</a> by <a href="https://risehere.net/">Rise</a>
<br>
移植自 <a href="https://mak1t0.cc/" target="_blank" rel="noreferrer noopener">Makito</a>'s <a href="https://github.com/SumiMakito/hexo-theme-journal/" target="_blank" rel="noreferrer noopener">Journal.</a> <br>
<br>

&copy;
	
	Faye
	

    </div>
    
</div><div id="extraContainer" class="extra-container">
    
    
    <div class="toc animated-visibility" :class="{ invisible: scrollY <= 140 }">


	<div class="toc-content">
	
		
		
		
		<center>- 目录 -</center>
		
		
		<ul>
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e6%a6%82%e7%8e%87%e5%88%86%e5%b8%83%e4%b8%8e%e7%86%b5%e7%bc%96%e7%a0%81" onclick="onNavClick(`#概率分布与熵编码-nav`)" id="概率分布与熵编码-nav">
									概率分布与熵编码
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e9%87%8f%e5%8c%96%e4%b8%8d%e5%8f%af%e5%af%bc" onclick="onNavClick(`#量化不可导-nav`)" id="量化不可导-nav">
									量化不可导
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%9d%87%e5%8c%80%e5%99%aa%e5%a3%b0%e6%b6%89%e5%8f%8a%e5%88%b0%e7%9a%84%e6%a6%82%e7%8e%87%e5%85%b3%e7%b3%bb" onclick="onNavClick(`#均匀噪声涉及到的概率关系-nav`)" id="均匀噪声涉及到的概率关系-nav">
									均匀噪声涉及到的概率关系
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#compressai-%e4%bb%a3%e7%a0%81%e4%b8%ad%e7%9a%84%e7%86%b5%e6%a8%a1%e5%9e%8b" onclick="onNavClick(`#compressai-代码中的熵模型-nav`)" id="compressai-代码中的熵模型-nav">
									CompressAI 代码中的熵模型
								</a>
							</li>
						
						
					
				
			
		</ul>
	</div>

</div>
    
    <div class="pagination">
        <a id="globalBackToTop" class="pagination-action animated-visibility" href="#top" :class="{ invisible: scrollY == 0 }">
            <i class="material-icons pagination-action-icon">
                keyboard_arrow_up
            </i>
        </a>
        
        <a type="button" class="pagination-action" id="darkModeToggleButton">
            <span class="material-icons pagination-action-icon" id="darkModeToggleIcon">
                dark_mode
            </span>
        </a>
        
        
    </div>
</div>
<div class="single-column-drawer-container" id="drawer"
     v-bind:class="{ 'single-column-drawer-container-active': isDrawerOpen }">
    <div class="drawer-content">
        <div class="drawer-menu">
            
            
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/posts">
                    归档
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/categories">
                    分类
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/tags">
                    标签
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/about">
                    关于
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/index.xml">
                    RSS
                </a>
                
            
            
            <div class="toc">


	<div class="toc-content">
	
		
		
		
		<center>- 目录 -</center>
		
		
		<ul>
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e6%a6%82%e7%8e%87%e5%88%86%e5%b8%83%e4%b8%8e%e7%86%b5%e7%bc%96%e7%a0%81" onclick="onNavClick(`#概率分布与熵编码-nav`)" id="概率分布与熵编码-nav">
									概率分布与熵编码
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e9%87%8f%e5%8c%96%e4%b8%8d%e5%8f%af%e5%af%bc" onclick="onNavClick(`#量化不可导-nav`)" id="量化不可导-nav">
									量化不可导
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%9d%87%e5%8c%80%e5%99%aa%e5%a3%b0%e6%b6%89%e5%8f%8a%e5%88%b0%e7%9a%84%e6%a6%82%e7%8e%87%e5%85%b3%e7%b3%bb" onclick="onNavClick(`#均匀噪声涉及到的概率关系-nav`)" id="均匀噪声涉及到的概率关系-nav">
									均匀噪声涉及到的概率关系
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#compressai-%e4%bb%a3%e7%a0%81%e4%b8%ad%e7%9a%84%e7%86%b5%e6%a8%a1%e5%9e%8b" onclick="onNavClick(`#compressai-代码中的熵模型-nav`)" id="compressai-代码中的熵模型-nav">
									CompressAI 代码中的熵模型
								</a>
							</li>
						
						
					
				
			
		</ul>
	</div>

</div>
            
        </div>
    </div>
</div>
<transition name="fade">
    <div id="drawer-mask" v-bind:class="{ 'single-column-drawer-mask': mounted }" v-if="isDrawerOpen" v-on:click="toggleDrawer"></div>
</transition>
<nav id="navBar" class="navbar sticky-top navbar-light single-column-nav-container">
    <div id="navBackground" class="nav-background"></div>
    <div class="container container-narrow nav-content">
        <button id="nav_dropdown_btn" class="nav-dropdown-toggle" type="button" v-on:click="toggleDrawer">
            <i class="material-icons">
                menu
            </i>
        </button>
        <a id="navTitle" class="navbar-brand" href="https://imfaye.me/">
            PIKA☆NCHI
        </a>
        
        <button type="button" class="nav-darkmode-toggle" id="darkModeToggleButton2">
            <i class="material-icons" id="darkModeToggleIcon2">
                dark_mode
            </i>
        </button>
        
    </div>
</nav>
<div class="single-column-header-container" id="pageHead"
     v-bind:style="{ transform: 'translateZ(0px) translateY('+.3*scrollY+'px)', opacity: 1-navOpacity }">
    <a href="https://imfaye.me/">
        <div class="single-column-header-title">PIKA☆NCHI</div>
        
        <div class="single-column-header-subtitle">Faye&#39;s Blog</div>
        

    </a>
</div>

            <div id="content">
                <div id="streamContainer" class="stream-container">

    <div class="post-list-container post-list-container-shadow">
        <div class="post">
            
            
            
                
            

            <div class="post-head-wrapper"
                
                    
                    
                    style="background-image: url('https://raw.githubusercontent.com/bygonexf/Blog-Images/master/2023/02/upgit_20230225_1677304856.png')"
                    
                
            >
                <div class="post-title">
                    端到端图像/视频压缩里的熵模型
                    
                    <div class="post-subtitle">
                        理论&amp;代码分析
                    </div>
                    
                    <div class="post-meta">
                        
                        <time itemprop="datePublished">
                            2022-04-20 17:04
                        </time>
                        

                        
                            <i class="material-icons" style="">folder</i>
                                <a href="/categories/">[有情笔记]</a>
                                &nbsp;
                        

                        
                            <i class="material-icons" style="">label</i>
                            
                                <a href="/tags/%E5%9B%BE%E5%83%8F%E7%BC%96%E7%A0%81">图像编码</a>
                                &nbsp;
                            
                                <a href="/tags/%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81">视频编码</a>
                                &nbsp;
                            
                        
                        
                    </div>
                </div>
            </div>
            
            <div class="post-body-wrapper">
                
                <div class="post-body" v-pre>
                
                    <h2 id="概率分布与熵编码">概率分布与熵编码</h2>
<p>在端到端图像/视频压缩模型中，我们需要去尽可能精准地模拟待编码元素值的概率分布。一方面是为了更精确地进行码率估计，另一方面也是因为更精准的概率分布建模能使得熵编码环节更好地消除统计冗余节省码字。</p>
<p><img src="https://raw.githubusercontent.com/bygonexf/Blog-Images/master/2023/02/upgit_20230224_1677253790.png" alt="image-20230224234946517"></p>
<p>建模出概率分布后，在实际熵编码中，就可以通过概率分布生成熵编码器所需要的概率表。</p>
<p>多说一句，在传统编解码里，通常熵编码会采用自适应模型，即随着编码字符的输入，不断更新概率分布（自适应模型相比静态模型效率更高，符合局部性原理，适应符号概率忽大忽小的波动，如果能合理地利用上下文信息压缩效率可以远超静态模型）。然而在端到端压缩模型里，通常直接通过网络生成独立的概率分布的参数，不会随着编码过程更新概率表。</p>
<h2 id="量化不可导">量化不可导</h2>
<p>这个没什么好说的，量化四舍五入的取整操作显然是不可导的，所以在训练的时候可以通过加均匀噪声来替换四舍五入的操作。</p>
<p><img src="https://raw.githubusercontent.com/bygonexf/Blog-Images/master/2023/02/upgit_20230225_1677299134.png" alt="image-20230225122531069"></p>
<p>在训练阶段，我们会通过给待编码元素值加上-0.5到0.5的均匀噪声来替代量化操作。而实际推理的时候，就正常进行量化。</p>
<h2 id="均匀噪声涉及到的概率关系">均匀噪声涉及到的概率关系</h2>
<p><img src="https://raw.githubusercontent.com/bygonexf/Blog-Images/master/2023/02/upgit_20230225_1677304856.png" alt="image-20230225124013214"></p>
<p>首先明确一下这几条线分布代表什么。</p>
<p>$p_{y_i}$：编码空间元素值的概率密度函数</p>
<p>$p_{\tilde{y_i}}$：$y_i$ 加上均匀噪声后的概率密度函数</p>
<p>$p_{\hat{y_i}}$：$y_i$量化后的概率质量函数（量化后就成了离散型变量了）</p>
<p>均匀噪声其实就是均匀分布 $U(-0.5, 0.5)$，$y_i$ 加上均匀噪声得到 $\tilde{y_i}$，两个独立的连续随机变量的和的概率分布公式是 $f_{X+Y}(z) = \int_{-\infty}^{\infty} f_X(x) f_Y(z-x) ,\mathrm{d}x$，直观来说也很好理解，对于任意 $\tilde{y_i}$ 值为 $c$，可能加均匀噪声得到 $c$ 的 $y_i$ 取值范围其实就是 $c-0.5$ 到 $c+0.5$，$p_{\tilde{y_i}}$ 在 $c$ 点的值其实就可以通过 $p_{y_i}$ 在 $c-0.5$ 到 $c+0.5$ 的积分得出。</p>
<p>对于每个整数点，也自然符合上述描述。</p>
<p><img src="https://raw.githubusercontent.com/bygonexf/Blog-Images/master/2023/02/upgit_20230225_1677304320.png" alt="image-20230225135158633"></p>
<p>而这样一来，加均匀噪声得到的 $p_{\tilde{y_i}}$ 最妙的性质就在于，在每个整数点 $p_{\tilde{y_i}}$ 的值和实际量化得到的离散变量 $p_{\hat{y_i}}$ 在这一点的概率质量相等。</p>
<p>所以说，加均匀噪声这一操作，本质上类似于在给 $p_{\hat{y_i}}$ 的概率质量函数作插值，类似于一个连续松弛 (continuous relaxation) 的操作。</p>
<p>此外，我们在端到端模型里通常去建模的也就是这个 $p_{y_i}$，而这里其实是假设 $p_{y_i}$ 近似一个拉普拉斯分布，实际代码实现中，有一部分模型采用拉普拉斯分布去建模，也有一部分模型，比如 CompressAI，是采用高斯分布去建模的。</p>
<h2 id="compressai-代码中的熵模型">CompressAI 代码中的熵模型</h2>
<p>以其中的 GaussianConditional 熵模型为例，稍微讲一下实际实现的时候一些常见操作。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">forward</span>(
</span></span><span style="display:flex;"><span>        self,
</span></span><span style="display:flex;"><span>        inputs: Tensor,
</span></span><span style="display:flex;"><span>        scales: Tensor,
</span></span><span style="display:flex;"><span>        means: Optional[Tensor] = <span style="color:#8b008b;font-weight:bold">None</span>,
</span></span><span style="display:flex;"><span>        training: Optional[<span style="color:#658b00">bool</span>] = <span style="color:#8b008b;font-weight:bold">None</span>,
</span></span><span style="display:flex;"><span>    ) -&gt; Tuple[Tensor, Tensor]:
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">if</span> training <span style="color:#8b008b">is</span> <span style="color:#8b008b;font-weight:bold">None</span>:
</span></span><span style="display:flex;"><span>            training = self.training
</span></span><span style="display:flex;"><span>        outputs = self.quantize(inputs, <span style="color:#cd5555">&#34;noise&#34;</span> <span style="color:#8b008b;font-weight:bold">if</span> training <span style="color:#8b008b;font-weight:bold">else</span> <span style="color:#cd5555">&#34;dequantize&#34;</span>, means)
</span></span><span style="display:flex;"><span>        likelihood = self._likelihood(outputs, scales, means)
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">if</span> self.use_likelihood_bound:
</span></span><span style="display:flex;"><span>            likelihood = self.likelihood_lower_bound(likelihood)
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">return</span> outputs, likelihood
</span></span></code></pre></div><p>训练的时候和上面说的一样，通过加均匀噪声替代量化操作。</p>
<p>而其中这个 <code>likelihood</code> 其实就是用于码率估计的，网络会输出 $y_i$ 值，然后我们叠加均匀噪声，而网络也会输出 $p_{y_i}$ 建模为高斯分布的 $\mu$ 和 $\sigma$ 值，这样其实我们就能计算出当前条件下 $p_{\tilde{y_i}}$ 的特定取值。后面再用 $-log_2 x$ 就能算出估计出的码字比特大小。</p>
<p>再来看一下实际熵编解码的实现，以编码为例。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">compress</span>(self, inputs, indexes, means=<span style="color:#8b008b;font-weight:bold">None</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        Compress input tensors to char strings.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        Args:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">            inputs (torch.Tensor): input tensors
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">            indexes (torch.IntTensor): tensors CDF indexes
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">            means (torch.Tensor, optional): optional tensor means
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        symbols = self.quantize(inputs, <span style="color:#cd5555">&#34;symbols&#34;</span>, means)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">if</span> <span style="color:#658b00">len</span>(inputs.size()) &lt; <span style="color:#b452cd">2</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#8b008b;font-weight:bold">raise</span> <span style="color:#008b45;font-weight:bold">ValueError</span>(
</span></span><span style="display:flex;"><span>                <span style="color:#cd5555">&#34;Invalid `inputs` size. Expected a tensor with at least 2 dimensions.&#34;</span>
</span></span><span style="display:flex;"><span>            )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">if</span> inputs.size() != indexes.size():
</span></span><span style="display:flex;"><span>            <span style="color:#8b008b;font-weight:bold">raise</span> <span style="color:#008b45;font-weight:bold">ValueError</span>(<span style="color:#cd5555">&#34;`inputs` and `indexes` should have the same size.&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self._check_cdf_size()
</span></span><span style="display:flex;"><span>        self._check_cdf_length()
</span></span><span style="display:flex;"><span>        self._check_offsets_size()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        strings = []
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">for</span> i <span style="color:#8b008b">in</span> <span style="color:#658b00">range</span>(symbols.size(<span style="color:#b452cd">0</span>)):
</span></span><span style="display:flex;"><span>            rv = self.entropy_coder.encode_with_indexes(
</span></span><span style="display:flex;"><span>                symbols[i].reshape(-<span style="color:#b452cd">1</span>).int().tolist(),
</span></span><span style="display:flex;"><span>                indexes[i].reshape(-<span style="color:#b452cd">1</span>).int().tolist(),
</span></span><span style="display:flex;"><span>                self._quantized_cdf.tolist(),
</span></span><span style="display:flex;"><span>                self._cdf_length.reshape(-<span style="color:#b452cd">1</span>).int().tolist(),
</span></span><span style="display:flex;"><span>                self._offset.reshape(-<span style="color:#b452cd">1</span>).int().tolist(),
</span></span><span style="display:flex;"><span>            )
</span></span><span style="display:flex;"><span>            strings.append(rv)
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">return</span> strings
</span></span></code></pre></div><p><code>symbols</code> 就是量化后的待编码值减去网络预测出的高斯分布的均值，这样后面熵编码就可以统一用准备好的不同方差的零均值高斯采样的 cdf 表。再注意一下这里的 <code>indexes</code> ，下文会讲。</p>
<p>上面说的 cdf 表可以通过这个更新函数看一下实现过程。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">update</span>(self):
</span></span><span style="display:flex;"><span>        multiplier = -self._standardized_quantile(self.tail_mass / <span style="color:#b452cd">2</span>)
</span></span><span style="display:flex;"><span>        pmf_center = torch.ceil(self.scale_table * multiplier).int()
</span></span><span style="display:flex;"><span>        pmf_length = <span style="color:#b452cd">2</span> * pmf_center + <span style="color:#b452cd">1</span>
</span></span><span style="display:flex;"><span>        max_length = torch.max(pmf_length).item()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        device = pmf_center.device
</span></span><span style="display:flex;"><span>        samples = torch.abs(
</span></span><span style="display:flex;"><span>            torch.arange(max_length, device=device).int() - pmf_center[:, <span style="color:#8b008b;font-weight:bold">None</span>]
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        samples_scale = self.scale_table.unsqueeze(<span style="color:#b452cd">1</span>)
</span></span><span style="display:flex;"><span>        samples = samples.float()
</span></span><span style="display:flex;"><span>        samples_scale = samples_scale.float()
</span></span><span style="display:flex;"><span>        upper = self._standardized_cumulative((<span style="color:#b452cd">0.5</span> - samples) / samples_scale)
</span></span><span style="display:flex;"><span>        lower = self._standardized_cumulative((-<span style="color:#b452cd">0.5</span> - samples) / samples_scale)
</span></span><span style="display:flex;"><span>        pmf = upper - lower
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        tail_mass = <span style="color:#b452cd">2</span> * lower[:, :<span style="color:#b452cd">1</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        quantized_cdf = torch.Tensor(<span style="color:#658b00">len</span>(pmf_length), max_length + <span style="color:#b452cd">2</span>)
</span></span><span style="display:flex;"><span>        quantized_cdf = self._pmf_to_cdf(pmf, tail_mass, pmf_length, max_length)
</span></span><span style="display:flex;"><span>        self._quantized_cdf = quantized_cdf
</span></span><span style="display:flex;"><span>        self._offset = -pmf_center
</span></span><span style="display:flex;"><span>        self._cdf_length = pmf_length + <span style="color:#b452cd">2</span>
</span></span></code></pre></div><p>可以看到，cdf 表其实是一定数量采样的 scale 值对应的零均值高斯分布（转化后的 $p_{y_i}$）在一定数量采样点上计算好 $p_{\tilde{y_i}}$ 的值。</p>
<p>这里其实有两处采样：</p>
<ol>
<li>采样 scale （对应 index ，index 指明取 cdf 表哪个分布）</li>
<li>对于分布采样一系列的点计算概率值 （对应 cdf 表中每个分布）</li>
</ol>
<p>可以通过 <code>build_indexes</code> 来看一下 indexes 的确定过程。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">build_indexes</span>(self, scales: Tensor) -&gt; Tensor:
</span></span><span style="display:flex;"><span>        scales = self.lower_bound_scale(scales)
</span></span><span style="display:flex;"><span>        indexes = scales.new_full(scales.size(), <span style="color:#658b00">len</span>(self.scale_table) - <span style="color:#b452cd">1</span>).int()
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">for</span> s <span style="color:#8b008b">in</span> self.scale_table[:-<span style="color:#b452cd">1</span>]:
</span></span><span style="display:flex;"><span>            indexes -= (scales &lt;= s).int()
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">return</span> indexes
</span></span></code></pre></div><p><code>indexes</code> 是通过 <code>scales</code> 来确定的，具体来说 <code>index</code> 其实是之前说的一系列采样的 scale 值里小于等于当前 scale 的最接近它的采样 scale 的编号。</p>

                    
                    <HR width="100%" id="EOF">
		    <p style="color:#777;">最后修改于 2022-04-20</p>
                    
                </div>
            </div>
            
            
            <nav class="post-pagination">

                
                <a class="newer-posts" href="/post/vae/">
			下回<br>耶，VAE
                </a>
                
                
                
                <a class="older-posts" href="/post/dcn-and-optical-flow/">
			上回<br>可变形卷积与光流
                </a>
                
            </nav>
            <div class="post-comment-wrapper">
                










            </div>
        </div>
    </div>


                    </div>
            </div><div id="single-column-footer">
Hugo Theme <a href="https://github.com/amazingrise/hugo-theme-diary">Diary</a> by <a href="https://risehere.net/">Rise</a>
<br>
移植自 <a href="https://mak1t0.cc/" target="_blank" rel="noreferrer noopener">Makito</a>'s <a href="https://github.com/SumiMakito/hexo-theme-journal/" target="_blank" rel="noreferrer noopener">Journal.</a> <br>
<br>

&copy;
	
	Faye
	
</div>
            </div>
    
    <script src="/js/journal.js"></script></body>
</html>
